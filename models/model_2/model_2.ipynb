{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9752b44a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "# load filenames for human and dog images\n",
    "human_files = np.array(glob(\"/data/lfw/*/*\"))\n",
    "dog_files = np.array(glob(\"/data/dog_images/*/*/*\"))\n",
    "\n",
    "# print number of images in each dataset\n",
    "print('There are %d total human images.' % len(human_files))\n",
    "print('There are %d total dog images.' % len(dog_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd007fd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import cv2                \n",
    "import matplotlib.pyplot as plt                        \n",
    "%matplotlib inline                               \n",
    "\n",
    "# extract pre-trained face detector\n",
    "face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_alt.xml')\n",
    "\n",
    "# load color (BGR) image\n",
    "img = cv2.imread(human_files[0])\n",
    "# convert BGR image to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# find faces in image\n",
    "faces = face_cascade.detectMultiScale(gray)\n",
    "\n",
    "# print number of faces detected in the image\n",
    "print('Number of faces detected:', len(faces))\n",
    "\n",
    "# get bounding box for each detected face\n",
    "for (x,y,w,h) in faces:\n",
    "    # add bounding box to color image\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    \n",
    "# convert BGR image to RGB for plotting\n",
    "cv_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# display the image, along with bounding box\n",
    "plt.imshow(cv_rgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d48afc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# returns \"True\" if face is detected in image stored at img_path\n",
    "def face_detector(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray)\n",
    "    return len(faces) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2c1d59",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "human_files_short = human_files[:100]\n",
    "dog_files_short = dog_files[:100]\n",
    "\n",
    "#-#-# Do NOT modify the code above this line. #-#-#\n",
    "\n",
    "## TODO: Test the performance of the face_detector algorithm \n",
    "## on the images in human_files_short and dog_files_short.\n",
    "count_humans = 0 \n",
    "count_dogs = 0\n",
    "\n",
    "num_filesh = len(human_files_short)\n",
    "num_filesd = len(dog_files_short)\n",
    "\n",
    "for file in human_files_short:\n",
    "    if face_detector(file) == True:\n",
    "        count_humans += 1\n",
    "        \n",
    "for file in dog_files_short:\n",
    "    if face_detector(file) == True:\n",
    "        count_dogs += 1\n",
    "        \n",
    "\n",
    "\n",
    "print('Haar Face Detection')\n",
    "print('The percentage of the detected face - Humans:{0:.0%}'.format(count_humans / num_filesh))\n",
    "print('The percentage of the detected face - Dogs:{0:.0%}'.format(count_dogs / num_filesd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f486e7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "# define VGG16 model\n",
    "VGG16 = models.vgg16(pretrained=True)\n",
    "\n",
    "# check if CUDA is available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "# move model to GPU if CUDA is available\n",
    "if use_cuda:\n",
    "    VGG16 = VGG16.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2871cc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "def load_convert_image_to_tensor(img_path):    \n",
    "    image = Image.open(img_path).convert('RGB')\n",
    "    # resize to (244, 244) because VGG16 accept this shape\n",
    "    in_transform = transforms.Compose([\n",
    "                        transforms.Resize(size=(244, 244)),\n",
    "                        transforms.ToTensor()]) # normalization .\n",
    "\n",
    "    # discard the transparent, alpha channel (that's the :3) and add the batch dimension\n",
    "    image = in_transform(image)[:3,:,:].unsqueeze(0)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce77f2cd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# helper function for un-normalizing an image  - from STYLE TRANSFER exercise\n",
    "# and converting it from a Tensor image to a NumPy image for display\n",
    "def image_convert(tensor):\n",
    "    \"\"\" Display a tensor as an image. \"\"\"\n",
    "    \n",
    "    image = tensor.to(\"cpu\").clone().detach()\n",
    "    image = image.numpy().squeeze()\n",
    "    image = image.transpose(1,2,0)\n",
    "    image = image * np.array((0.229, 0.224, 0.225)) + np.array((0.485, 0.456, 0.406))\n",
    "    image = image.clip(0, 1)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30ae351",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dog_image = Image.open('/data/dog_images/train/001.Affenpinscher/Affenpinscher_00001.jpg')\n",
    "plt.imshow(dog_image)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
